#!/usr/bin/env bash

# exit on error
set -e

SCRIPT_DIR="$(cd -- "$(dirname -- "${BASH_SOURCE[0]}")" && pwd)"
source "${SCRIPT_DIR}/../shared.sh"

events_new_table=$(
  cat <<'EOF'
create or replace table events_new
(
    `id` UUID COMMENT 'unique event id' CODEC(LZ4),
    `team_id` UUID COMMENT 'associated team id' CODEC(LZ4),
    `app_id` UUID COMMENT 'associated app id' CODEC(LZ4),
    `session_id` UUID COMMENT 'associated session id' CODEC(LZ4),
    `timestamp` DateTime64(3, 'UTC') COMMENT 'event timestamp' CODEC(DoubleDelta, ZSTD(3)),
    `inserted_at` DateTime64(3, 'UTC') DEFAULT now64() COMMENT 'original event insertion timestamp' CODEC(Delta(8), ZSTD(3)),
    `type` LowCardinality(String) COMMENT 'type of the event' CODEC(ZSTD(3)),
    `user_triggered` Bool COMMENT 'true if user chose to trigger by themselves' CODEC(ZSTD(3)),
    `inet.ipv4` Nullable(IPv4) COMMENT 'ipv4 address' CODEC(ZSTD(3)),
    `inet.ipv6` Nullable(IPv6) COMMENT 'ipv6 address' CODEC(ZSTD(3)),
    `inet.country_code` LowCardinality(String) COMMENT 'country code' CODEC(ZSTD(3)),
    `attribute.installation_id` UUID COMMENT 'unique id for an installation of an app, generated by sdk' CODEC(LZ4),
    `attribute.app_version` LowCardinality(String) COMMENT 'app version identifier' CODEC(ZSTD(3)),
    `attribute.app_build` LowCardinality(String) COMMENT 'app build identifier' CODEC(ZSTD(3)),
    `attribute.app_unique_id` LowCardinality(String) COMMENT 'app bundle identifier' CODEC(ZSTD(3)),
    `attribute.platform` LowCardinality(String) COMMENT 'platform identifier' CODEC(ZSTD(3)),
    `attribute.measure_sdk_version` String COMMENT 'measure sdk version identifier' CODEC(ZSTD(3)),
    `attribute.thread_name` String COMMENT 'thread on which the event was captured' CODEC(ZSTD(3)),
    `attribute.user_id` String COMMENT 'id of the app\'s end user' CODEC(ZSTD(3)),
    `attribute.device_name` String COMMENT 'name of the device' CODEC(ZSTD(3)),
    `attribute.device_model` String COMMENT 'model of the device' CODEC(ZSTD(3)),
    `attribute.device_manufacturer` String COMMENT 'manufacturer of the device' CODEC(ZSTD(3)),
    `attribute.device_type` LowCardinality(String) COMMENT 'type of the device, like phone or tablet' CODEC(ZSTD(3)),
    `attribute.device_is_foldable` Bool COMMENT 'true for foldable devices' CODEC(ZSTD(3)),
    `attribute.device_is_physical` Bool COMMENT 'true for physical devices' CODEC(ZSTD(3)),
    `attribute.device_density_dpi` UInt16 COMMENT 'dpi density' CODEC(Delta(2), ZSTD(3)),
    `attribute.device_width_px` UInt16 COMMENT 'screen width' CODEC(Delta(2), ZSTD(3)),
    `attribute.device_height_px` UInt16 COMMENT 'screen height' CODEC(Delta(2), ZSTD(3)),
    `attribute.device_density` Float32 COMMENT 'device density' CODEC(Delta(4), ZSTD(3)),
    `attribute.device_locale` LowCardinality(String) COMMENT 'rfc 5646 locale string' CODEC(ZSTD(3)),
    `attribute.device_low_power_mode` Bool COMMENT 'true if low power mode is enabled',
    `attribute.device_thermal_throttling_enabled` Bool COMMENT 'true if thermal throttling is enabled',
    `attribute.device_cpu_arch` LowCardinality(String) COMMENT 'cpu architecture like arm64 and so on',
    `attribute.os_name` LowCardinality(String) COMMENT 'name of the operating system' CODEC(ZSTD(3)),
    `attribute.os_version` String COMMENT 'version of the operating system' CODEC(ZSTD(3)),
    `attribute.os_page_size` UInt8 COMMENT 'memory_page_size' CODEC(Delta(1), ZSTD(3)),
    `attribute.network_type` LowCardinality(String) COMMENT 'either - wifi, cellular, vpn, unknown, no_network' CODEC(ZSTD(3)),
    `attribute.network_generation` LowCardinality(String) COMMENT 'either - 2g, 3g, 4g, 5g, unknown' CODEC(ZSTD(3)),
    `attribute.network_provider` String COMMENT 'name of the network service provider' CODEC(ZSTD(3)),
    `user_defined_attribute` Map(LowCardinality(String), Tuple(
        Enum8('string' = 1, 'int64' = 2, 'float64' = 3, 'bool' = 4),
        String)) COMMENT 'user defined attributes' CODEC(ZSTD(3)),
    `anr.handled` Bool COMMENT 'anr was handled by the application code' CODEC(ZSTD(3)),
    `anr.fingerprint` String COMMENT 'fingerprint for anr similarity classification' CODEC(ZSTD(3)),
    `anr.exceptions` String COMMENT 'anr exception data' CODEC(ZSTD(3)),
    `anr.threads` String COMMENT 'anr thread data' CODEC(ZSTD(3)),
    `anr.foreground` Bool COMMENT 'true if the anr was perceived by end user' CODEC(ZSTD(3)),
    `exception.handled` Bool COMMENT 'exception was handled by application code' CODEC(ZSTD(3)),
    `exception.fingerprint` String COMMENT 'fingerprint for exception similarity classification' CODEC(ZSTD(3)),
    `exception.exceptions` String COMMENT 'exception data' CODEC(ZSTD(3)),
    `exception.threads` String COMMENT 'exception thread data' CODEC(ZSTD(3)),
    `exception.foreground` Bool COMMENT 'true if the exception was perceived by end user' CODEC(ZSTD(3)),
    `exception.framework` String COMMENT 'the framework in which the exception was thrown',
    `exception.binary_images` String COMMENT 'list of apple crash binary images',
    `exception.error` String COMMENT 'general error data',
    `app_exit.reason` LowCardinality(String) COMMENT 'reason for app exit' CODEC(ZSTD(3)),
    `app_exit.importance` LowCardinality(String) COMMENT 'importance of process that it used to have before death' CODEC(ZSTD(3)),
    `app_exit.trace` String COMMENT 'modified trace given by ApplicationExitInfo to help debug anrs.' CODEC(ZSTD(3)),
    `app_exit.process_name` String COMMENT 'name of the process that died' CODEC(ZSTD(3)),
    `app_exit.pid` String COMMENT 'id of the process that died' CODEC(ZSTD(3)),
    `string.severity_text` LowCardinality(String) COMMENT 'log level - info, warning, error, fatal, debug' CODEC(ZSTD(3)),
    `string.string` String COMMENT 'log message text' CODEC(ZSTD(3)),
    `gesture_long_click.target` String COMMENT 'class or instance name of the originating view' CODEC(ZSTD(3)),
    `gesture_long_click.target_id` String COMMENT 'unique identifier of the target' CODEC(ZSTD(3)),
    `gesture_long_click.touch_down_time` UInt64 COMMENT 'time for touch down gesture' CODEC(T64, ZSTD(3)),
    `gesture_long_click.touch_up_time` UInt64 COMMENT 'time for touch up gesture' CODEC(T64, ZSTD(3)),
    `gesture_long_click.width` UInt16 COMMENT 'width of the target view in pixels' CODEC(T64, ZSTD(3)),
    `gesture_long_click.height` UInt16 COMMENT 'height of the target view in pixels' CODEC(T64, ZSTD(3)),
    `gesture_long_click.x` Float32 COMMENT 'x coordinate of where the gesture happened' CODEC(Delta(4), ZSTD(3)),
    `gesture_long_click.y` Float32 COMMENT 'y coordinate of where the gesture happened' CODEC(Delta(4), ZSTD(3)),
    `gesture_click.target` String COMMENT 'class or instance name of the originating view' CODEC(ZSTD(3)),
    `gesture_click.target_id` String COMMENT 'unique identifier of the target' CODEC(ZSTD(3)),
    `gesture_click.touch_down_time` UInt64 COMMENT 'time for touch down gesture' CODEC(T64, ZSTD(3)),
    `gesture_click.touch_up_time` UInt64 COMMENT 'time for the touch up gesture' CODEC(T64, ZSTD(3)),
    `gesture_click.width` UInt16 COMMENT 'width of the target view in pixels' CODEC(Delta(2), ZSTD(3)),
    `gesture_click.height` UInt16 COMMENT 'height of the target view in pixels' CODEC(Delta(2), ZSTD(3)),
    `gesture_click.x` Float32 COMMENT 'x coordinate of where the gesture happened' CODEC(Delta(4), ZSTD(3)),
    `gesture_click.y` Float32 COMMENT 'y coordinate of where the gesture happened' CODEC(Delta(4), ZSTD(3)),
    `gesture_scroll.target` String COMMENT 'class or instance name of the originating view' CODEC(ZSTD(3)),
    `gesture_scroll.target_id` String COMMENT 'unique identifier of the target' CODEC(ZSTD(3)),
    `gesture_scroll.touch_down_time` UInt64 COMMENT 'time for touch down gesture' CODEC(T64, ZSTD(3)),
    `gesture_scroll.touch_up_time` UInt64 COMMENT 'time for touch up gesture' CODEC(T64, ZSTD(3)),
    `gesture_scroll.x` Float32 COMMENT 'x coordinate of where the gesture started' CODEC(Delta(4), ZSTD(3)),
    `gesture_scroll.y` Float32 COMMENT 'y coordinate of where the gesture started' CODEC(Delta(4), ZSTD(3)),
    `gesture_scroll.end_x` Float32 COMMENT 'x coordinate of where the gesture ended' CODEC(Delta(4), ZSTD(3)),
    `gesture_scroll.end_y` Float32 COMMENT 'y coordinate of where the gesture ended' CODEC(Delta(4), ZSTD(3)),
    `gesture_scroll.direction` LowCardinality(String) COMMENT 'direction of the scroll' CODEC(ZSTD(3)),
    `lifecycle_activity.type` LowCardinality(String) COMMENT 'type of the lifecycle activity, either - created, resumed, paused, destroyed' CODEC(ZSTD(3)),
    `lifecycle_activity.class_name` String COMMENT 'fully qualified class name of the activity' CODEC(ZSTD(3)),
    `lifecycle_activity.intent` String COMMENT 'intent data serialized as string' CODEC(ZSTD(3)),
    `lifecycle_activity.saved_instance_state` Bool COMMENT 'represents that activity was recreated with a saved state. only available for type created.' CODEC(ZSTD(3)),
    `lifecycle_fragment.type` LowCardinality(String) COMMENT 'type of the lifecycle fragment, either - attached, resumed, paused, detached' CODEC(ZSTD(3)),
    `lifecycle_fragment.class_name` String COMMENT 'fully qualified class name of the fragment' CODEC(ZSTD(3)),
    `lifecycle_fragment.parent_activity` String COMMENT 'fully qualified class name of the parent activity that the fragment is attached to' CODEC(ZSTD(3)),
    `lifecycle_fragment.parent_fragment` String COMMENT 'fully qualified class name of the parent fragment that the fragment is attached to' CODEC(ZSTD(3)),
    `lifecycle_fragment.tag` String COMMENT 'optional fragment tag' CODEC(ZSTD(3)),
    `lifecycle_view_controller.type` LowCardinality(String) COMMENT 'type of the iOS ViewController lifecycle event',
    `lifecycle_view_controller.class_name` LowCardinality(String) COMMENT 'class name of the iOS ViewController lifecycle event',
    `lifecycle_swift_ui.type` LowCardinality(String) COMMENT 'type of the iOS SwiftUI view lifecycle event',
    `lifecycle_swift_ui.class_name` LowCardinality(String) COMMENT 'class name of the iOS SwiftUI view lifecycle event',
    `lifecycle_app.type` LowCardinality(String) COMMENT 'type of the lifecycle app, either - background, foreground' CODEC(ZSTD(3)),
    `cold_launch.process_start_uptime` UInt64 COMMENT 'start uptime in msec' CODEC(T64, ZSTD(3)),
    `cold_launch.process_start_requested_uptime` UInt64 COMMENT 'start uptime in msec' CODEC(T64, ZSTD(3)),
    `cold_launch.content_provider_attach_uptime` UInt64 COMMENT 'start uptime in msec' CODEC(T64, ZSTD(3)),
    `cold_launch.on_next_draw_uptime` UInt64 COMMENT 'time at which app became visible' CODEC(T64, ZSTD(3)),
    `cold_launch.launched_activity` String COMMENT 'activity which drew the first frame during cold launch' CODEC(ZSTD(3)),
    `cold_launch.has_saved_state` Bool COMMENT 'whether the launched_activity was created with a saved state bundle' CODEC(ZSTD(3)),
    `cold_launch.intent_data` String COMMENT 'intent data used to launch the launched_activity' CODEC(ZSTD(3)),
    `cold_launch.duration` UInt32 COMMENT 'computed cold launch duration' CODEC(T64, ZSTD(3)),
    `warm_launch.app_visible_uptime` UInt64 COMMENT 'time since the app became visible to user, in msec',
    `warm_launch.process_start_uptime` UInt64 COMMENT 'start uptime in msec' CODEC(T64, ZSTD(3)),
    `warm_launch.process_start_requested_uptime` UInt64 COMMENT 'start uptime in msec' CODEC(T64, ZSTD(3)),
    `warm_launch.content_provider_attach_uptime` UInt64 COMMENT 'start uptime in msec' CODEC(T64, ZSTD(3)),
    `warm_launch.on_next_draw_uptime` UInt64 COMMENT 'time at which app became visible to user, in msec' CODEC(ZSTD(3)),
    `warm_launch.launched_activity` String COMMENT 'activity which drew the first frame during warm launch' CODEC(ZSTD(3)),
    `warm_launch.has_saved_state` Bool COMMENT 'whether the launched_activity was created with a saved state bundle' CODEC(ZSTD(3)),
    `warm_launch.intent_data` String COMMENT 'intent data used to launch the launched_activity' CODEC(ZSTD(3)),
    `warm_launch.duration` UInt32 COMMENT 'computed warm launch duration' CODEC(T64, ZSTD(3)),
    `warm_launch.is_lukewarm` Bool COMMENT 'whether it is a lukewarm launch' CODEC(ZSTD(3)),
    `hot_launch.app_visible_uptime` UInt64 COMMENT 'time elapsed since the app became visible to user, in msec' CODEC(T64, ZSTD(3)),
    `hot_launch.on_next_draw_uptime` UInt64 COMMENT 'time at which app became visible to user, in msec' CODEC(T64, ZSTD(3)),
    `hot_launch.launched_activity` String COMMENT 'activity which drew the first frame during hot launch' CODEC(ZSTD(3)),
    `hot_launch.has_saved_state` Bool COMMENT 'whether the launched_activity was created with a saved state bundle' CODEC(ZSTD(3)),
    `hot_launch.intent_data` String COMMENT 'intent data used to launch the launched_activity' CODEC(ZSTD(3)),
    `hot_launch.duration` UInt32 COMMENT 'computed hot launch duration' CODEC(T64, ZSTD(3)),
    `network_change.network_type` LowCardinality(String) COMMENT 'type of the network, wifi, cellular etc' CODEC(ZSTD(3)),
    `network_change.previous_network_type` LowCardinality(String) COMMENT 'type of the previous network' CODEC(ZSTD(3)),
    `network_change.network_generation` LowCardinality(String) COMMENT '2g, 3g, 4g etc' CODEC(ZSTD(3)),
    `network_change.previous_network_generation` LowCardinality(String) COMMENT 'previous network generation' CODEC(ZSTD(3)),
    `network_change.network_provider` String COMMENT 'name of the network service provider' CODEC(ZSTD(3)),
    `http.url` String COMMENT 'url of the http request' CODEC(ZSTD(3)),
    `http.method` LowCardinality(String) COMMENT 'method like get, post' CODEC(ZSTD(3)),
    `http.status_code` UInt16 COMMENT 'http status code' CODEC(T64, ZSTD(3)),
    `http.start_time` UInt64 COMMENT 'uptime at when the http call started, in msec' CODEC(T64, ZSTD(3)),
    `http.end_time` UInt64 COMMENT 'uptime at when the http call ended, in msec' CODEC(T64, ZSTD(3)),
    `http_request_headers` Map(String, String) COMMENT 'http request headers' CODEC(ZSTD(3)),
    `http_response_headers` Map(String, String) COMMENT 'http response headers' CODEC(ZSTD(3)),
    `http.request_body` String COMMENT 'request body' CODEC(ZSTD(3)),
    `http.response_body` String COMMENT 'response body' CODEC(ZSTD(3)),
    `http.failure_reason` String COMMENT 'reason for failure' CODEC(ZSTD(3)),
    `http.failure_description` String COMMENT 'description of the failure' CODEC(ZSTD(3)),
    `http.client` LowCardinality(String) COMMENT 'name of the http client' CODEC(ZSTD(3)),
    `memory_usage.java_max_heap` UInt64 COMMENT 'maximum size of the java heap allocated, in kb' CODEC(T64, ZSTD(3)),
    `memory_usage.java_total_heap` UInt64 COMMENT 'total size of the java heap available for allocation, in KB' CODEC(T64, ZSTD(3)),
    `memory_usage.java_free_heap` UInt64 COMMENT 'free memory available in the java heap, in kb' CODEC(T64, ZSTD(3)),
    `memory_usage.total_pss` UInt64 COMMENT 'total proportional set size - amount of memory used by the process, including shared memory and code. in kb.' CODEC(T64, ZSTD(3)),
    `memory_usage.rss` UInt64 COMMENT 'resident set size - amount of physical memory currently used, in kb' CODEC(T64, ZSTD(3)),
    `memory_usage.native_total_heap` UInt64 COMMENT 'total size of the native heap (memory out of java\'s control) available for allocation, in kb' CODEC(T64, ZSTD(3)),
    `memory_usage.native_free_heap` UInt64 COMMENT 'amount of free memory available in the native heap, in kb' CODEC(T64, ZSTD(3)),
    `memory_usage.interval` UInt64 COMMENT 'interval between two consecutive readings, in msec' CODEC(T64, ZSTD(3)),
    `memory_usage_absolute.max_memory` UInt64 COMMENT 'maximum memory available to the application, in KiB',
    `memory_usage_absolute.used_memory` UInt64 COMMENT 'used memory by the application, in KiB',
    `memory_usage_absolute.interval` UInt64 COMMENT 'interval between two consecutive readings',
    `low_memory.java_max_heap` UInt64 COMMENT 'maximum size of the java heap allocated, in kb' CODEC(T64, ZSTD(3)),
    `low_memory.java_total_heap` UInt64 COMMENT 'total size of the java heap available for allocation, in kb' CODEC(T64, ZSTD(3)),
    `low_memory.java_free_heap` UInt64 COMMENT 'free memory available in the java heap, in kb' CODEC(T64, ZSTD(3)),
    `low_memory.total_pss` UInt64 COMMENT 'total proportional set size - amount of memory used by the process, including shared memory and code. in kb.' CODEC(T64, ZSTD(3)),
    `low_memory.rss` UInt64 COMMENT 'resident set size - amount of physical memory currently used, in kb' CODEC(T64, ZSTD(3)),
    `low_memory.native_total_heap` UInt64 COMMENT 'total size of the native heap (memory out of java' CODEC(T64, ZSTD(3)),
    `low_memory.native_free_heap` UInt64 COMMENT 'amount of free memory available in the native heap, in kb' CODEC(T64, ZSTD(3)),
    `trim_memory.level` LowCardinality(String) COMMENT 'one of the trim memory constants as received by component callback' CODEC(ZSTD(3)),
    `cpu_usage.num_cores` UInt8 COMMENT 'number of cores on the device' CODEC(T64, ZSTD(3)),
    `cpu_usage.clock_speed` UInt64 COMMENT 'clock speed of the processor, in hz' CODEC(T64, ZSTD(3)),
    `cpu_usage.start_time` UInt64 COMMENT 'process start time, in jiffies' CODEC(T64, ZSTD(3)),
    `cpu_usage.uptime` UInt64 COMMENT 'time since the device booted, in msec' CODEC(T64, ZSTD(3)),
    `cpu_usage.utime` UInt64 COMMENT 'execution time in user mode, in jiffies' CODEC(T64, ZSTD(3)),
    `cpu_usage.cutime` UInt64 COMMENT 'execution time in user mode with child processes, in jiffies' CODEC(T64, ZSTD(3)),
    `cpu_usage.stime` UInt64 COMMENT 'execution time in kernel mode, in jiffies' CODEC(T64, ZSTD(3)),
    `cpu_usage.cstime` UInt64 COMMENT 'execution time in user mode with child processes, in jiffies' CODEC(T64, ZSTD(3)),
    `cpu_usage.interval` UInt64 COMMENT 'interval between two consecutive readings, in msec' CODEC(T64, ZSTD(3)),
    `cpu_usage.percentage_usage` Float64 COMMENT 'percentage of cpu usage in the interval' CODEC(DoubleDelta, ZSTD(3)),
    `navigation.to` String COMMENT 'destination page or screen where the navigation led to' CODEC(ZSTD(3)),
    `navigation.from` String COMMENT 'source page or screen from where the navigation was triggered' CODEC(ZSTD(3)),
    `navigation.source` String COMMENT 'how the event was collected example a library or framework name' CODEC(ZSTD(3)),
    `screen_view.name` String COMMENT 'name of the screen viewed' CODEC(ZSTD(3)),
    `bug_report.description` String COMMENT 'description of the bug report',
    `custom.name` LowCardinality(String) COMMENT 'name of the custom event',
    `attachments` String COMMENT 'attachment metadata' CODEC(ZSTD(3)),
    INDEX type_idx type TYPE set(100) GRANULARITY 2,
    INDEX exception_handled_idx `exception.handled` TYPE minmax GRANULARITY 2,
    INDEX attribute_os_name_idx `attribute.os_name` TYPE minmax GRANULARITY 2,
    INDEX attribute_os_version_idx `attribute.os_version` TYPE minmax GRANULARITY 2,
    INDEX inet_country_code_idx `inet.country_code` TYPE minmax GRANULARITY 2,
    INDEX attribute_device_name_idx `attribute.device_name` TYPE minmax GRANULARITY 2,
    INDEX attribute_device_manufacturer_idx `attribute.device_manufacturer` TYPE minmax GRANULARITY 2,
    INDEX attribute_device_locale_idx `attribute.device_locale` TYPE minmax GRANULARITY 2,
    INDEX attribute_network_provider_idx `attribute.network_provider` TYPE minmax GRANULARITY 2,
    INDEX attribute_network_type_idx `attribute.network_type` TYPE minmax GRANULARITY 2,
    INDEX exception_fingerprint_bloom_idx `exception.fingerprint` TYPE bloom_filter GRANULARITY 4,
    INDEX anr_fingerprint_bloom_idx `anr.fingerprint` TYPE bloom_filter GRANULARITY 4,
    INDEX user_defined_attribute_key_bloom_idx mapKeys(user_defined_attribute) TYPE bloom_filter(0.01) GRANULARITY 16,
    INDEX user_defined_attribute_key_minmax_idx mapKeys(user_defined_attribute) TYPE minmax GRANULARITY 16,
    INDEX custom_name_bloom_idx `custom.name` TYPE bloom_filter GRANULARITY 2
)
ENGINE = ReplacingMergeTree
PARTITION BY toYYYYMM(timestamp)
ORDER BY (team_id, app_id, attribute.app_version, attribute.app_build, session_id, timestamp, id)
SETTINGS index_granularity = 8192
COMMENT 'events root table'
EOF
)

app_filters_new_table=$(
  cat <<'EOF'
create or replace table app_filters_new
(
    `team_id` UUID CODEC(ZSTD(3)),
    `app_id` UUID COMMENT 'associated app id' CODEC(LZ4),
    `end_of_month` DateTime COMMENT 'last day of the month' CODEC(DoubleDelta, ZSTD(3)),
    `app_version` Tuple(
        LowCardinality(String),
        LowCardinality(String)) COMMENT 'composite app version' CODEC(ZSTD(3)),
    `os_version` Tuple(
        LowCardinality(String),
        LowCardinality(String)) COMMENT 'composite os version' CODEC(ZSTD(3)),
    `country_code` LowCardinality(String) COMMENT 'country code' CODEC(ZSTD(3)),
    `network_provider` LowCardinality(String) COMMENT 'network provider' CODEC(ZSTD(3)),
    `network_type` LowCardinality(String) COMMENT 'network type' CODEC(ZSTD(3)),
    `network_generation` LowCardinality(String) COMMENT 'network generation' CODEC(ZSTD(3)),
    `device_locale` LowCardinality(String) COMMENT 'device locale' CODEC(ZSTD(3)),
    `device_manufacturer` LowCardinality(String) COMMENT 'device manufacturer' CODEC(ZSTD(3)),
    `device_name` LowCardinality(String) COMMENT 'device name' CODEC(ZSTD(3)),
    `exception` Bool COMMENT 'true if source is exception event' CODEC(ZSTD(3)),
    `anr` Bool COMMENT 'true if source is anr event' CODEC(ZSTD(3)),
)
ENGINE = ReplacingMergeTree
PARTITION BY toYYYYMM(end_of_month)
PRIMARY KEY (team_id, app_id, end_of_month)
ORDER BY (team_id, app_id, end_of_month, app_version, os_version, country_code, network_provider, network_type, network_generation, device_locale, device_manufacturer, device_name, exception, anr)
SETTINGS index_granularity = 8192
COMMENT 'derived app filters'
EOF
)

app_metrics_new_table=$(
  cat <<'EOF'
create or replace table app_metrics_new
(
    `team_id` UUID CODEC(ZSTD(3)),
    `app_id` UUID COMMENT 'associated app id' CODEC(ZSTD(3)),
    `timestamp` DateTime64(3, 'UTC') COMMENT 'interval metrics will be aggregated to' CODEC(DoubleDelta, ZSTD(3)),
    `app_version` Tuple(
        LowCardinality(String),
        LowCardinality(String)) COMMENT 'composite app version' CODEC(ZSTD(3)),
    `unique_sessions` AggregateFunction(uniq, UUID) COMMENT 'unique sessions in interval window' CODEC(ZSTD(3)),
    `crash_sessions` AggregateFunction(uniq, UUID) COMMENT 'crash sessions in interval window' CODEC(ZSTD(3)),
    `perceived_crash_sessions` AggregateFunction(uniq, UUID) COMMENT 'perceived crash sessions in interval window' CODEC(ZSTD(3)),
    `anr_sessions` AggregateFunction(uniq, UUID) COMMENT 'anr sessions in interval window' CODEC(ZSTD(3)),
    `perceived_anr_sessions` AggregateFunction(uniq, UUID) COMMENT 'perceived anr sessions in interval window' CODEC(ZSTD(3)),
    `cold_launch_p95` AggregateFunction(quantile(0.95), UInt32) COMMENT 'p95 quantile of cold launch duration' CODEC(ZSTD(3)),
    `warm_launch_p95` AggregateFunction(quantile(0.95), UInt32) COMMENT 'p95 quantile of warm launch duration' CODEC(ZSTD(3)),
    `hot_launch_p95` AggregateFunction(quantile(0.95), UInt32) COMMENT 'p95 quantile of hot launch duration' CODEC(ZSTD(3)),
    index app_version_name_idx app_version.1 type set(100) granularity 2,
    index app_version_code_idx app_version.2 type set(100) granularity 2
)
ENGINE = AggregatingMergeTree
PARTITION BY toYYYYMM(timestamp)
ORDER BY (team_id, app_id, timestamp)
SETTINGS index_granularity = 8192
COMMENT 'aggregated app metrics by a fixed time window'
EOF
)

journey_new_table=$(
  cat <<'EOF'
create or replace table journey_new
(
  `id` UUID comment 'unique event id' CODEC(LZ4),
  `team_id` UUID comment 'associated team id' CODEC(LZ4),
  `app_id` UUID comment 'associated app id' CODEC(LZ4),
  `session_id` UUID comment 'associated session id' CODEC(LZ4),
  `timestamp` DateTime64(3, 'UTC') comment 'event timestamp' CODEC(DoubleDelta, ZSTD(3)),
  `inserted_at` DateTime64(3, 'UTC') comment 'original event insertion timestamp' CODEC(Delta(8), ZSTD(3)),
  `type` LowCardinality(String) COMMENT 'type of the event' CODEC(ZSTD(3)),
  `app_version` Tuple(LowCardinality(String), LowCardinality(String)) COMMENT 'app version identifier' CODEC(ZSTD(3)),
  `exception.handled` Bool COMMENT 'exception was handled by application code' CODEC(ZSTD(3)),
  `lifecycle_activity.type` LowCardinality(String) COMMENT 'type of the lifecycle activity, either - created, resumed, paused, destroyed' CODEC(ZSTD(3)),
  `lifecycle_activity.class_name` String COMMENT 'fully qualified class name of the activity' CODEC(ZSTD(3)),
  `lifecycle_fragment.type` LowCardinality(String) COMMENT 'type of the lifecycle fragment, either - attached, resumed, paused, detached' CODEC(ZSTD(3)),
  `lifecycle_fragment.class_name` String COMMENT 'fully qualified class name of the fragment' CODEC(ZSTD(3)),
  `lifecycle_fragment.parent_activity` String COMMENT 'fully qualified class name of the parent activity that the fragment is attached to' CODEC(ZSTD(3)),
  `lifecycle_fragment.parent_fragment` String COMMENT 'fully qualified class name of the parent fragment that the fragment is attached to' CODEC(ZSTD(3)),
  `lifecycle_view_controller.type` LowCardinality(String) COMMENT 'type of the iOS ViewController lifecycle event',
  `lifecycle_view_controller.class_name` LowCardinality(String) COMMENT 'class name of the iOS ViewController lifecycle event',
  `lifecycle_swift_ui.type` LowCardinality(String) COMMENT 'type of the iOS SwiftUI view lifecycle event',
  `lifecycle_swift_ui.class_name` LowCardinality(String) COMMENT 'class name of the iOS SwiftUI view lifecycle event',
  `screen_view.name` String COMMENT 'name of the screen viewed' CODEC(ZSTD(3))
)
engine = ReplacingMergeTree
partition by toYYYYMM(timestamp)
order by (team_id, app_id, app_version.1, app_version.2, timestamp)
comment 'journey events';
EOF
)

sessions_index_new_table=$(
  cat <<'EOF'
create or replace table sessions_index_new
(
    `team_id` UUID comment 'associated team id' CODEC(LZ4),
    `app_id` UUID comment 'associated app id' CODEC(LZ4),
    `app_version` Tuple(
        LowCardinality(String),
        LowCardinality(String)) comment 'associated app version' CODEC(LZ4),
    `session_id` UUID comment 'associated session id' CODEC(LZ4),
    `first_event_timestamp` DateTime64(3) comment 'first event timestamp of the block of events' CODEC(DoubleDelta, ZSTD(3)),
    `last_event_timestamp` DateTime64(3) comment 'last event timestamp of the block of events' CODEC(DoubleDelta, ZSTD(3))
)
engine = MergeTree
partition by toYYYYMM(first_event_timestamp)
order by (team_id, app_id, session_id)
settings index_granularity = 1024
comment 'index of keys for sessions to make fast session detail queries'
EOF
)

sessions_new_table=$(
  cat <<'EOF'
create or replace table sessions_new
(
    `session_id` UUID COMMENT 'session id' CODEC(ZSTD(3)),
    `team_id` UUID CODEC(ZSTD(3)),
    `app_id` UUID COMMENT 'unique id of th app' CODEC(ZSTD(3)),
    `first_event_timestamp` SimpleAggregateFunction(min, DateTime64(3, 'UTC')) COMMENT 'timestamp of the first event' CODEC(DoubleDelta, ZSTD(3)),
    `last_event_timestamp` SimpleAggregateFunction(max, DateTime64(3, 'UTC')) COMMENT 'timestamp of the last event' CODEC(DoubleDelta, ZSTD(3)),
    `app_version` Tuple(
        LowCardinality(String),
        LowCardinality(String)) COMMENT 'composite app version' CODEC(ZSTD(3)),
    `os_version` Tuple(
        LowCardinality(String),
        LowCardinality(String)) COMMENT 'composite os version' CODEC(ZSTD(3)),
    `country_codes` AggregateFunction(groupUniqArray, LowCardinality(String)) comment 'list of all unique country codes',
    `network_providers` AggregateFunction(groupUniqArray, LowCardinality(String)) comment 'list of all unique network service providers',
    `network_types` AggregateFunction(groupUniqArray, LowCardinality(String)) comment 'list of all unique network types',
    `network_generations` AggregateFunction(groupUniqArray, LowCardinality(String)) comment 'list of all unique network generations',
    `device_locales` AggregateFunction(groupUniqArray, LowCardinality(String)) comment 'list of all unique device locales',
    `device_manufacturer` LowCardinality(String) COMMENT 'manufacturer of the device' CODEC(ZSTD(3)),
    `device_name` LowCardinality(String) COMMENT 'name of the device' CODEC(ZSTD(3)),
    `device_model` LowCardinality(String) COMMENT 'model of the device' CODEC(ZSTD(3)),
    `user_ids` AggregateFunction(groupUniqArray, String) comment 'list of all user ids',
    `unique_types` AggregateFunction(groupUniqArray, LowCardinality(String)) COMMENT 'list of unique event type' CODEC(ZSTD(3)),
    `unique_strings` AggregateFunction(groupUniqArray, String) COMMENT 'list of unique log string values' CODEC(ZSTD(3)),
    `unique_view_classnames` AggregateFunction(groupUniqArray, String) COMMENT 'list of unique view class names' CODEC(ZSTD(3)),
    `unique_subview_classnames` AggregateFunction(groupUniqArray, String) COMMENT 'list of unique subview class names' CODEC(ZSTD(3)),
    `unique_exceptions` AggregateFunction(groupUniqArray, Tuple(
        type String,
        message String,
        file_name String,
        class_name String,
        method_name String)) COMMENT 'list of unique tuples of exception details' CODEC(ZSTD(3)),
    `unique_anrs` AggregateFunction(groupUniqArray, Tuple(
        type String,
        message String,
        file_name String,
        class_name String,
        method_name String)) COMMENT 'list of unique tuples of anr details' CODEC(ZSTD(3)),
    `unique_click_targets` AggregateFunction(groupUniqArray, Tuple(
        String,
        String)) COMMENT 'list of unique tuples of click targets and ids' CODEC(ZSTD(3)),
    `unique_longclick_targets` AggregateFunction(groupUniqArray, Tuple(
        String,
        String)) COMMENT 'list of unique tuples of long click targets and ids' CODEC(ZSTD(3)),
    `unique_scroll_targets` AggregateFunction(groupUniqArray, Tuple(
        String,
        String)) COMMENT 'list of unique tuples of scroll targets and ids' CODEC(ZSTD(3)),
    `event_count` AggregateFunction(sum, UInt64) COMMENT 'count of events in this session' CODEC(ZSTD(3)),
    `crash_count` AggregateFunction(sum, UInt64) COMMENT 'count of crash events in this session' CODEC(ZSTD(3)),
    `anr_count` AggregateFunction(sum, UInt64) COMMENT 'count of ANR events in this session' CODEC(ZSTD(3)),
    `bug_report_count` AggregateFunction(sum, UInt64) COMMENT 'count of bug report events in this session' CODEC(ZSTD(3)),
    `background_count` AggregateFunction(sum, UInt64) COMMENT 'count of background events in this session' CODEC(ZSTD(3)),
    `foreground_count` AggregateFunction(sum, UInt64) COMMENT 'count of foreground events in this session' CODEC(ZSTD(3)),
    `event_type_counts` AggregateFunction(sumMap, Tuple(Array(String), Array(UInt64))) COMMENT 'count of event types in this session' CODEC(ZSTD(3)),
    INDEX first_event_timestamp_minmax_idx first_event_timestamp TYPE minmax GRANULARITY 1,
    INDEX last_event_timestamp_minmax_idx last_event_timestamp TYPE minmax GRANULARITY 1,
    -- INDEX user_id_bloom_idx user_id TYPE bloom_filter GRANULARITY 2,
)
ENGINE = AggregatingMergeTree
PARTITION BY toYYYYMM(first_event_timestamp)
ORDER BY (team_id, app_id, app_version.1, app_version.2, session_id)
SETTINGS index_granularity = 8192
COMMENT 'aggregated app sessions'
EOF
)

# unhandled_exception_groups_new_table=$(
#   cat <<'EOF'
# create or replace table unhandled_exception_groups_new
# (
#     `team_id` UUID comment 'associated team id' CODEC(ZSTD(3)),
#     `app_id` UUID comment 'linked app id' CODEC(ZSTD(3)),
#     `id` FixedString(32) comment 'unique fingerprint of the unhandled exception which acts as the id of the group' CODEC(ZSTD(3)),
#     `type` String comment 'type of the exception' CODEC(ZSTD(3)),
#     `message` String comment 'message of the exception' CODEC(ZSTD(3)),
#     `method_name` String comment 'method name where the exception occured' CODEC(ZSTD(3)),
#     `file_name` String comment 'file name where the exception occured' CODEC(ZSTD(3)),
#     `line_number` Int32 comment 'line number where the exception occured' CODEC(ZSTD(3)),
#     `count` UInt64 comment 'count of unhandled exception instances' CODEC(ZSTD(3)),
#     `created_at` DateTime64(3, 'UTC') comment 'utc timestamp at the time of record creation' CODEC(DoubleDelta, ZSTD(3)),
#     `updated_at` DateTime64(3, 'UTC') comment 'utc timestamp at the time of record updation' CODEC(DoubleDelta, ZSTD(3))
# )
# ENGINE = ReplacingMergeTree
# PARTITION BY toYYYYMM(created_at)
# ORDER BY (team_id, app_id, id)
# SETTINGS
#   index_granularity = 2048,
#   enable_block_number_column= 1,
#   enable_block_offset_column = 1
# COMMENT 'unhandled exception groups'
# EOF
# )

unhandled_exception_groups_new_table=$(
  cat <<'EOF'
create or replace table unhandled_exception_groups_new
(
    `team_id` UUID comment 'associated team id' CODEC(ZSTD(3)),
    `app_id` UUID comment 'linked app id' CODEC(ZSTD(3)),
    `id` FixedString(32) comment 'unique fingerprint of the unhandled exception which acts as the id of the group' CODEC(ZSTD(3)),
    `type` String comment 'type of the exception' CODEC(ZSTD(3)),
    `message` String comment 'message of the exception' CODEC(ZSTD(3)),
    `method_name` String comment 'method name where the exception occured' CODEC(ZSTD(3)),
    `file_name` String comment 'file name where the exception occured' CODEC(ZSTD(3)),
    `line_number` Int32 comment 'line number where the exception occured' CODEC(ZSTD(3)),
    `count` UInt64 comment 'count of unhandled exception instances' CODEC(ZSTD(3)),
    `created_at` DateTime64(3, 'UTC') comment 'utc timestamp at the time of record creation' CODEC(DoubleDelta, ZSTD(3)),
    `updated_at` DateTime64(3, 'UTC') comment 'utc timestamp at the time of record updation' CODEC(DoubleDelta, ZSTD(3))
)
ENGINE = ReplacingMergeTree
PARTITION BY toYYYYMM(created_at)
ORDER BY (team_id, app_id, id)
SETTINGS index_granularity = 2048
COMMENT 'unhandled exception groups'
EOF
)

anr_groups_new_table=$(
  cat <<'EOF'
create or replace table anr_groups_new
(
    `team_id` UUID comment 'associated team id' CODEC(ZSTD(3)),
    `app_id` UUID comment 'linked app id' CODEC(ZSTD(3)),
    `id` FixedString(32) comment 'unique fingerprint of the unhandled exception which acts as the id of the group' CODEC(ZSTD(3)),
    `type` String comment 'type of the exception' CODEC(ZSTD(3)),
    `message` String comment 'message of the exception' CODEC(ZSTD(3)),
    `method_name` String comment 'method name where the exception occured' CODEC(ZSTD(3)),
    `file_name` String comment 'file name where the exception occured' CODEC(ZSTD(3)),
    `line_number` Int32 comment 'line number where the exception occured' CODEC(ZSTD(3)),
    `count` UInt64 comment 'count of anr instances' CODEC(ZSTD(3)),
    `created_at` DateTime64(3, 'UTC') comment 'utc timestamp at the time of record creation' CODEC(DoubleDelta, ZSTD(3)),
    `updated_at` DateTime64(3, 'UTC') comment 'utc timestamp at the time of record updation' CODEC(DoubleDelta, ZSTD(3))
)
ENGINE = ReplacingMergeTree
PARTITION BY toYYYYMM(created_at)
ORDER BY (team_id, app_id, id)
SETTINGS index_granularity = 2048
COMMENT 'ANR groups'
EOF
)

app_filters_mv() {
  local mv_name="$1"
  local source="$2"
  local dest="$3"

  cat <<EOF
  create materialized view $mv_name to $dest
  (
    \`team_id\` UUID,
    \`app_id\` UUID,
    \`end_of_month\` Date,
    \`app_version\` Tuple(LowCardinality(String), LowCardinality(String)),
    \`os_version\` Tuple(LowCardinality(String), LowCardinality(String)),
    \`country_code\` LowCardinality(String),
    \`network_provider\` LowCardinality(String),
    \`network_type\` LowCardinality(String),
    \`network_generation\` LowCardinality(String),
    \`device_locale\` LowCardinality(String),
    \`device_manufacturer\` LowCardinality(String),
    \`device_name\` LowCardinality(String),
    \`exception\` Bool,
    \`anr\` Bool
  ) as select
      team_id,
      app_id,
      toLastDayOfMonth(timestamp) as end_of_month,
      (attribute.app_version, attribute.app_build) as app_version,
      (attribute.os_name, attribute.os_version) as os_version,
      inet.country_code as country_code,
      attribute.network_provider as network_provider,
      attribute.network_type as network_type,
      attribute.network_generation as network_generation,
      attribute.device_locale as device_locale,
      attribute.device_manufacturer as device_manufacturer,
      attribute.device_name as device_name,
      max(type = 'exception' and exception.handled = 0) as exception,
      max(type = 'anr') as anr
    from $source
    where
      attribute.os_name != ''
      and attribute.os_version != ''
      and inet.country_code != ''
      and attribute.network_provider != ''
      and attribute.network_type != ''
      and attribute.network_generation != ''
      and attribute.device_locale != ''
      and attribute.device_manufacturer != ''
      and attribute.device_name != ''
    group by
      team_id,
      app_id,
      end_of_month,
      app_version,
      os_version,
      country_code,
      network_provider,
      network_type,
      network_generation,
      device_locale,
      device_manufacturer,
      device_name
EOF
}

app_metrics_mv() {
  local mv_name="$1"
  local source="$2"
  local dest="$3"

  cat <<EOF
  create materialized view $mv_name
  to $dest
  as
  select
      team_id,
      app_id,
      toStartOfFifteenMinutes(timestamp) as timestamp,
      (attribute.app_version, attribute.app_build) as app_version,
      uniqState(session_id) as unique_sessions,
      uniqStateIf(session_id, type = 'exception' and exception.handled = 0) as crash_sessions,
      uniqStateIf(session_id, type = 'exception' and exception.handled = 0 and exception.foreground = 1) as perceived_crash_sessions,
      uniqStateIf(session_id, type = 'anr') as anr_sessions,
      uniqStateIf(session_id, type = 'anr' and anr.foreground = 1) as perceived_anr_sessions,
      quantileStateIf(0.95)(cold_launch.duration, type = 'cold_launch' and cold_launch.duration > 0 and cold_launch.duration <= 30000) as cold_launch_p95,
      quantileStateIf(0.95)(warm_launch.duration, type = 'warm_launch' and warm_launch.duration > 0 and warm_launch.duration <= 10000) as warm_launch_p95,
      quantileStateIf(0.95)(hot_launch.duration, type = 'hot_launch' and hot_launch.duration > 0) as hot_launch_p95
  from $source
  group by
      team_id,
      app_id,
      timestamp,
      app_version;
EOF
}

journey_mv() {
  local mv_name="$1"
  local source="$2"
  local dest="$3"

  cat <<EOF
create materialized view $mv_name
to $dest
as select
  id,
  team_id,
  app_id,
  session_id,
  timestamp,
  inserted_at,
  type,
  (attribute.app_version, attribute.app_build) as app_version,
  exception.handled,
  lifecycle_activity.type,
  lifecycle_activity.class_name,
  lifecycle_fragment.type,
  lifecycle_fragment.class_name,
  lifecycle_fragment.parent_activity,
  lifecycle_fragment.parent_fragment,
  lifecycle_view_controller.type,
  lifecycle_view_controller.class_name,
  lifecycle_swift_ui.type,
  lifecycle_swift_ui.class_name,
  screen_view.name
from $source
where type = 'lifecycle_activity'
      or type = 'lifecycle_fragment'
      or type = 'lifecycle_view_controller'
      or type = 'lifecycle_swift_ui'
      or type = 'screen_view'
      or type = 'exception'
      or type = 'anr'
;
EOF
}

sessions_index_mv() {
  local mv_name="$1"
  local source="$2"
  local dest="$3"

  cat <<EOF
  create materialized view $mv_name
  to $dest
  as
  select
    team_id,
    app_id,
    (attribute.app_version, attribute.app_build) as app_version,
    session_id,
    min(timestamp) as first_event_timestamp,
    max(timestamp) as last_event_timestamp
  from $source
  group by
    team_id,
    app_id,
    app_version,
    session_id
EOF
}

sessions_mv() {
  local mv_name="$1"
  local source="$2"
  local dest="$3"

  cat <<EOF
  create materialized view $mv_name
  to $dest
  as
  select
    session_id,
    team_id,
    app_id,
    (attribute.app_version, attribute.app_build) as app_version,
    (attribute.os_name, attribute.os_version) as os_version,
    min(timestamp) as first_event_timestamp,
    max(timestamp) as last_event_timestamp,
    groupUniqArrayState(\`attribute.user_id\`) as user_ids,
    groupUniqArrayState(\`inet.country_code\`) as country_codes,
    groupUniqArrayState(\`attribute.network_provider\`) as network_providers,
    groupUniqArrayState(\`attribute.network_type\`) as network_types,
    groupUniqArrayState(\`attribute.network_generation\`) as network_generations,
    groupUniqArrayState(\`type\`) as unique_types,
    groupUniqArrayState(\`string.string\`) as unique_strings,
    groupUniqArrayStateIf(lifecycle_activity.class_name, type = 'lifecycle_activity' and lifecycle_activity.class_name != '') as unique_view_classnames,
    groupUniqArrayStateIf(lifecycle_fragment.class_name, type = 'lifecycle_fragment' and lifecycle_fragment.class_name != '') as unique_subview_classnames,
    groupUniqArrayStateIf(
      tuple(
        simpleJSONExtractString(\`exception.exceptions\`, 'type'),
        simpleJSONExtractString(\`exception.exceptions\`, 'message'),
        simpleJSONExtractString(\`exception.exceptions\`, 'file_name'),
        simpleJSONExtractString(\`exception.exceptions\`, 'class_name'),
        simpleJSONExtractString(\`exception.exceptions\`, 'method_name')
      ),
      type = 'exception' and exception.handled = 0
    ) as unique_exceptions,
    groupUniqArrayStateIf(
      tuple(
        simpleJSONExtractString(\`anr.exceptions\`, 'type'),
        simpleJSONExtractString(\`anr.exceptions\`, 'message'),
        simpleJSONExtractString(\`anr.exceptions\`, 'file_name'),
        simpleJSONExtractString(\`anr.exceptions\`, 'class_name'),
        simpleJSONExtractString(\`anr.exceptions\`, 'method_name')
      ),
      type = 'anr'
    ) as unique_anrs,
    groupUniqArrayStateIf(
      tuple(\`gesture_click.target\`, \`gesture_click.target_id\`),
      type = 'gesture_click'
    ) as unique_click_targets,
    groupUniqArrayStateIf(
      tuple(\`gesture_long_click.target\`, \`gesture_long_click.target_id\`),
      type = 'gesture_long_click'
    ) as unique_longclick_targets,
    groupUniqArrayStateIf(
      tuple(\`gesture_scroll.target\`, \`gesture_scroll.target_id\`),
      type = 'gesture_scroll'
    ) as unique_scroll_targets,
    sumState(toUInt64(1)) as event_count,
    sumStateIf(toUInt64(1), type = 'exception' and exception.handled = 0) as crash_count,
    sumStateIf(toUInt64(1), type = 'anr') as anr_count,
    sumStateIf(toUInt64(1), lifecycle_app.type = 'background') as background_count,
    sumStateIf(toUInt64(1), lifecycle_app.type = 'foreground') as foreground_count,
    sumMapState(tuple(array(type), array(toUInt64(1)))) as event_type_counts,
    argMax(\`attribute.device_name\`, timestamp) as device_name,
    argMax(\`attribute.device_manufacturer\`, timestamp) as device_manufacturer,
    argMax(\`attribute.device_model\`, timestamp) as device_model,
    groupUniqArrayState(\`attribute.device_locale\`) as device_locales
  from $source
  group by
    team_id,
    app_id,
    session_id,
    app_version,
    os_version
EOF
}

# connect to cloud database
USE_CLOUD=0

# replay chunk size
CHUNK_SIZE=10000

if [[ "$USE_CLOUD" -eq 1 ]]; then
  CHUNK_SIZE=10000000
fi

# list of partitions to migrate
# PARTITIONS=(202509 202510 202511 202512 202601)
PARTITIONS=(202511)

clickhouse_query() {
  local admin_user
  local admin_password
  local dbname

  admin_user=$(get_env_variable CLICKHOUSE_ADMIN_USER)
  admin_password=$(get_env_variable CLICKHOUSE_ADMIN_PASSWORD)
  dbname=measure

  if [[ "$USE_CLOUD" -eq 1 ]]; then
    host="mfntp88uzl.us-central1.gcp.clickhouse.cloud"
    clickhouse_client \
      --user "$admin_user" \
      --password "$admin_password" \
      --database "$dbname" \
      --host "$host" \
      --port 9440 \
      --secure \
      --progress \
      --receive_timeout 3600 \
      "$@"
  else
    clickhouse_client \
      --user "$admin_user" \
      --password "$admin_password" \
      --database "$dbname" \
      --receive_timeout 3600 \
      --progress \
      "$@"
  fi
}

create_resources() {
  echo "  ✔ Create new events"
  clickhouse_query --query "$events_new_table"

  echo "  ✔ Create new event filters"
  clickhouse_query --query "$app_filters_new_table"
  clickhouse_query --query "drop table if exists app_filters_new_mv sync"
  clickhouse_query --query "$(app_filters_mv 'app_filters_new_mv' 'events_new' 'app_filters_new')"

  echo "  ✔ Create new event metrics"
  clickhouse_query --query "$app_metrics_new_table"
  clickhouse_query --query "drop table if exists app_metrics_new_mv sync"
  clickhouse_query --query "$(app_metrics_mv 'app_metrics_new_mv' 'events_new' 'app_metrics_new')"

  echo "  ✔ Create new journey"
  clickhouse_query --query "$journey_new_table"
  clickhouse_query --query "drop table if exists journey_new_mv sync"
  clickhouse_query --query "$(journey_mv 'journey_new_mv' 'events_new' 'journey_new')"

  echo "  ✔ Create new sessions index"
  clickhouse_query --query "$sessions_index_new_table"
  clickhouse_query --query "drop table if exists sessions_index_new_mv sync"
  clickhouse_query --query "$(sessions_index_mv 'sessions_index_new_mv' 'events_new' 'sessions_index_new')"

  echo "  ✔ Create new sessions"
  clickhouse_query --query "$sessions_new_table"
  clickhouse_query --query "drop table if exists sessions_new_mv sync"
  clickhouse_query --query "$(sessions_mv 'sessions_new_mv' 'events_new' 'sessions_new')"

  echo "  ✔ Create new unhandled exception groups"
  clickhouse_query --query "$unhandled_exception_groups_new_table"

  echo "  ✔ Create new anr groups"
  clickhouse_query --query "$anr_groups_new_table"
}

replay_events() {
  echo "  ✔ Replaying events"

  if [[ "$USE_CLOUD" -eq 1 ]]; then
    if [[ ${#PARTITIONS[@]} -eq 0 ]]; then
      echo "  ✗ partitions array is empty – set it globally before calling replay_events in cloud mode"
      return 1
    fi

    echo "  ✔ Preparing row counts"
    local event_rows
    event_rows=$(count_rows 'events')
    local moved_rows=0

    for part in "${PARTITIONS[@]}"; do
      echo "  ✔ Starting partition $part"

      local offset=0
      while true; do
        local chunk_count
        chunk_count=$(clickhouse_query --query "
          select count()
          from (
            select 1
            from events
            where toYYYYMM(timestamp) = $part
            order by (app_id, session_id, timestamp, id)
            limit $CHUNK_SIZE offset $offset
          )
        ")

        # trim leading/trailing whitespace
        chunk_count=${chunk_count##[[:space:]]*}
        chunk_count=${chunk_count%%[[:space:]]*}

        if [[ -z "$chunk_count" || "$chunk_count" -eq 0 ]]; then
          echo "  ✔ Finished partition $part"
          break
        fi

        echo "  ✔ Replaying chunk of $chunk_count rows (offset $offset) in partition $part"

        if ! clickhouse_query --query "
          insert into events_new
          select
            id,
            team_id,
            app_id,
            session_id,
            timestamp,
            inserted_at,
            type,
            user_triggered,
            * except (
              id,
              team_id,
              app_id,
              session_id,
              timestamp,
              inserted_at,
              type,
              user_triggered
            )
          from events
          where toYYYYMM(timestamp) = $part
          order by (app_id, session_id, timestamp, id)
          limit $CHUNK_SIZE offset $offset
          settings
            min_insert_block_size_rows = 10484490,
            max_block_size = 100000,
            max_threads = 16
        "; then
          echo "  ✗ Insert failed at offset $offset in partition $part"
          return 1
        fi

        offset=$((offset + CHUNK_SIZE))
        moved_rows=$((moved_rows + CHUNK_SIZE))
        echo "  ✔ Progress ($((moved_rows / event_rows)))"
      done
    done

    echo "  ✔ Total Rows Moved: $moved_rows"
    echo "  ✔ Finished replaying all cloud partitions"
  else
    local offset=0
    while true; do
      local chunk_count
      chunk_count=$(clickhouse_query --query "
        select count()
        from (
          select 1
          from events
          order by (app_id, session_id, timestamp, id)
          limit $CHUNK_SIZE offset $offset
        )
      ")

      # trim leading/trailing whitespace
      chunk_count=${chunk_count##[[:space:]]*}
      chunk_count=${chunk_count%%[[:space:]]*}

      if [[ -z "$chunk_count" || "$chunk_count" -eq 0 ]]; then
        echo "  ✔ Finished replaying all events"
        break
      fi

      echo "  ✔ Replaying chunk of $chunk_count rows (offset $offset)"

      if ! clickhouse_query --query "
        insert into events_new
        select
          id,
          team_id,
          app_id,
          session_id,
          timestamp,
          inserted_at,
          type,
          user_triggered,
          * except (
            id,
            team_id,
            app_id,
            session_id,
            timestamp,
            inserted_at,
            type,
            user_triggered
          )
        from events
        order by (app_id, session_id, timestamp, id)
        limit $CHUNK_SIZE offset $offset
      "; then
        echo "  ✗ Insert failed at offset $offset"
        return 1
      fi

      offset=$((offset + CHUNK_SIZE))
    done
  fi
}

# replay_unhandled_exception_groups() {
#   echo "  ✔ Replaying unhandled_exception_groups"

#   if ! clickhouse_query --query "
#     insert into unhandled_exception_groups_new (
#       team_id,
#       app_id,
#       id,
#       type,
#       message,
#       method_name,
#       file_name,
#       line_number,
#       count,
#       created_at,
#       updated_at
#     )
#     select
#       g.team_id,
#       g.app_id,
#       g.id,
#       g.type,
#       g.message,
#       g.method_name,
#       g.file_name,
#       g.line_number,
#       coalesce(e.exception_count, 0) as count,
#       g.updated_at as created_at,
#       g.updated_at as updated_at
#     from unhandled_exception_groups as g
#     left join
#     (
#       select
#         team_id,
#         app_id,
#         exception.fingerprint as id,
#         count() as exception_count
#       from events_new
#       where
#         type = 'exception'
#         and exception.handled = false
#       group by
#         team_id,
#         app_id,
#         exception.fingerprint
#     ) as e
#     on g.team_id = e.team_id
#        and g.app_id = e.app_id
#        and g.id = e.id
#     order by (g.app_id, g.id)
#   "; then
#     echo "  ✗ Insert failed while replaying unhandled_exception_groups_new"
#     return 1
#   fi
# }

replay_unhandled_exception_groups() {
  echo "  ✔ Replaying unhandled_exception_groups"

  if ! clickhouse_query --query "
    insert into unhandled_exception_groups_new (
      team_id,
      app_id,
      id,
      type,
      message,
      method_name,
      file_name,
      line_number,
      count,
      created_at,
      updated_at
    )
    select
      g.team_id,
      g.app_id,
      g.id,
      g.type,
      g.message,
      g.method_name,
      g.file_name,
      g.line_number,
      coalesce(e.exception_count, 0) as count,
      g.updated_at as created_at,
      g.updated_at as updated_at
    from unhandled_exception_groups as g
    left join
    (
      select
        team_id,
        app_id,
        exception.fingerprint as id,
        count() as exception_count
      from events_new
      where
        type = 'exception'
        and exception.handled = false
      group by
        team_id,
        app_id,
        exception.fingerprint
    ) as e
    on g.team_id = e.team_id
       and g.app_id = e.app_id
       and g.id = e.id
    order by (g.app_id, g.id)
  "; then
    echo "  ✗ Insert failed while replaying unhandled_exception_groups_new"
    return 1
  fi
}

replay_anr_groups() {
  echo "  ✔ Replaying anr_groups"

  if ! clickhouse_query --query "
    insert into anr_groups_new (
      team_id,
      app_id,
      id,
      type,
      message,
      method_name,
      file_name,
      line_number,
      created_at,
      updated_at
    )
    select
      team_id,
      app_id,
      id,
      type,
      message,
      method_name,
      file_name,
      line_number,
      updated_at,
      updated_at
    from anr_groups
    order by (app_id, id)
  "; then
    echo "  ✗ Insert failed while replaying anr_groups_new"
    return 1
  fi
}

exchange_resources() {
  echo "  ✔ Exchange event filters"
  clickhouse_query --query "exchange tables app_filters_new and app_filters"

  echo "  ✔ Exchange event metrics"
  clickhouse_query --query "exchange tables app_metrics_new and app_metrics"

  echo "  ✔ Exchange journey"
  clickhouse_query --query "exchange tables journey_new and journey"

  # echo "  ✔ Exchange sessions index"
  # clickhouse_query --query "exchange tables sessions_index_new and sessions_index"

  echo "  ✔ Exchange sessions"
  clickhouse_query --query "exchange tables sessions_new and sessions"

  echo "  ✔ Exchange events"
  clickhouse_query --query "exchange tables events_new and events"

  echo "  ✔ Exchange unhandled exception groups"
  clickhouse_query --query "exchange tables unhandled_exception_groups_new and unhandled_exception_groups"

  echo "  ✔ Exchange anr groups"
  clickhouse_query --query "exchange tables anr_groups_new and anr_groups"
}

recreate_mvs() {
  echo "  ✔ Recreate event filters mv"
  clickhouse_query --query "drop table if exists app_filters_mv sync"
  clickhouse_query --query "$(app_filters_mv 'app_filters_mv' 'events' 'app_filters')"

  echo "  ✔ Recreate event metrics mv"
  clickhouse_query --query "drop table if exists app_metrics_mv sync"
  clickhouse_query --query "$(app_metrics_mv 'app_metrics_mv' 'events' 'app_metrics')"

  echo "  ✔ Recreate journey mv"
  clickhouse_query --query "drop table if exists journey_mv sync"
  clickhouse_query --query "$(journey_mv 'journey_mv' 'events' 'journey')"

  echo "  ✔ Recreate sessions index mv"
  clickhouse_query --query "drop table if exists sessions_index_mv sync"
  clickhouse_query --query "$(sessions_index_mv 'sessions_index_mv' 'events' 'sessions_index')"

  echo "  ✔ Recreate sessions mv"
  clickhouse_query --query "drop table if exists sessions_mv sync"
  clickhouse_query --query "$(sessions_mv 'sessions_mv' 'events' 'sessions')"
}

drop_resources() {
  echo "  ✔ Drop event filters"
  clickhouse_query --query "drop table if exists app_filters_new_mv sync"
  clickhouse_query --query "drop table if exists app_filters_new sync"

  echo "  ✔ Drop event metrics"
  clickhouse_query --query "drop table if exists app_metrics_new_mv sync"
  clickhouse_query --query "drop table if exists app_metrics_new sync"

  echo "  ✔ Drop journey"
  clickhouse_query --query "drop table if exists journey_new_mv sync"
  clickhouse_query --query "drop table if exists journey_new sync"

  echo "  ✔ Drop sessions"
  clickhouse_query --query "drop table if exists sessions_new_mv sync"
  clickhouse_query --query "drop table if exists sessions_new sync"

  echo "  ✔ Drop events"
  clickhouse_query --query "drop table if exists events_new sync"

  echo "  ✔ Drop unhandled_exception_groups"
  clickhouse_query --query "drop table if exists unhandled_exception_groups_new sync"

  echo "  ✔ Drop anr_groups"
  clickhouse_query --query "drop table if exists anr_groups_new sync"
}

verify_resources() {
  clickhouse_query --query "
  select
    (select count() from events final) as events_count,
    (select count() from events_new final) as events_new_count
  format
    PrettySpace
  "
  echo

  clickhouse_query --query "
  select
    (select count() from sessions final) as sessions_count,
    (select count() from sessions_new final) as sessions_new_count
  format
    PrettySpace
  "
  echo

  clickhouse_query --query "
  select
    (select count() from unhandled_exception_groups final) as unhandled_exception_groups_count,
    (select count() from unhandled_exception_groups_new final) as unhandled_exception_groups_new_count
  format
    PrettySpace
  "
  echo

  clickhouse_query --query "
  select
    (select count() from anr_groups final) as anr_groups_count,
    (select count() from anr_groups_new final) as anr_groups_new_count
  format
    PrettySpace
  "
}

# Counts the rows for partitions
#
# Args:
#   $1: The name of the table
#
# Returns:
#   Count of rows across the partitions
#   of the table.
count_rows() {
  printf -v joined "'%s', " "${PARTITIONS[@]}"
  joined="(${joined%, })"
  local table=$1
  local result

  result=$(clickhouse_query --query "
    select
      sum(rows) as rows
    from system.parts
    where
      database = 'measure'
      and table = '$table'
      and partition in $joined
  ")

  echo "$result"
}

# kick things off
check_base_dir
set_docker_compose

echo "Create resources..."
create_resources

echo
echo "Replay data..."
replay_events
echo
replay_unhandled_exception_groups
echo
replay_anr_groups
echo

echo "Verify backfill..."
verify_resources

# echo "Exchange resources..."
# exchange_resources

# echo "Recreate materialized views..."
# recreate_mvs

# echo "Drop resources..."
# drop_resources

# echo "Testing..."
# clickhouse_query --query "show tables;"
